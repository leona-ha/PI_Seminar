{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning & Deep Learning: GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein kleines Add-On, in dem ich Ihnen zeige, wie man die Grid Search und Random Search zur Optimierung der Hyperparameter anwendet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 1: Importiere relevante Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import helpers\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Validation libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, mean_squared_error, precision_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "# Display plots inside the notebook\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\", palette=\"pastel\")\n",
    "\n",
    "# Ignore warning related to pandas_profiling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Display all dataframe columns in outputs (it has 63 columns, which is wider than the notebook)\n",
    "# This sets it up to display with a horizontal scroll instead of hiding the middle columns\n",
    "pd.set_option('display.max_columns', 100) \n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Train und Test Datensatz festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit der Pickle Funktion packen wir den fertig bearbeiteten Dataframe in eine Datei, die wir nächste Woche einfach \n",
    "# importieren können. \n",
    "X = pd.read_pickle(\"X_df.pkl\")\n",
    "y = pd.read_pickle(\"y_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5 # wenn wir den seed festlegen können wir den random-split später reproduzieren\n",
    "test_size = 0.33 # d.h. 33% des Datensatzes werden zufällig ausgewählt und dem Test- Datensatz zugeordnet.\n",
    "\n",
    "# Durch den Train Test Split teilen wir den Datensatz in einen Train-Datensatz und einen Test-Datensatz auf. \n",
    "# Das Modell wird auf dem Train-Datensatz trainiert und am Test-Datensatz getestet.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung zur Evaluierung von Modellen:\n",
    "1. An den gleichen Daten trainieren und testen: Wir wissen nicht, ob das Modell auch für andere Daten gute Vorhersagen trifft. \n",
    "2. **Train/Test Split**: Teilt den Datensatz in zwei Teile auf, sodass an unterschiedlichen Daten gelernt und getestet wird. Bessere Schätzung der Out-of-Sample-Performance (=Generalisierung) als 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der K-fold Cross-Validation wir der Datensatz in K verschiedene Subsamples (=folds) unterteilt. Jeder fold wird dabei einmal als Test-Datensatz benutzt (während die restlichen **K-1** folds zum Training genutzt werden). So kann die Modell-Güte an verschiedenen Datensätzen getestet werden und ist somit objektiver. Das Ergebnis sind **K** Accuracy-Scores, aus denen i.d.R. der Mittelwert gebildet wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Grid Search zur Optimierung der Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Wiederholung: Ein **Hyperparameter** ist eine Eigenschaft des Modells, die vor dem Training manuell festgelegt wird und nicht aus den Daten gelernt werden kann. Beispiele sind C und gamma bei Support Vector Machines oder die Anzahl an Hidden Layers in Neural Networks. Im Gegensatz dazu werden **Model Parameter** aus den Daten geschätzt. Beispiele dafür sind die Support Vectors bei Support Vector Machines oder beta-Koeffizienten in der Logistischen Regression. \n",
    "\n",
    "Beim **Grid Search** wird eine Liste von möglichen Hyperparametern festgelegt. Dann werden systematisch **alle** Hyperparameter miteinander kombiniert und getestet, bis der beste Accuracy Score gefunden wurde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Modelle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Logistische Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search bei Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wenden wir Grid Search bei der Logistischen Regression an. Es werden verschiedene Werte für C und für die **penalty terms** (mehr dazu hier: https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c) angelegt und miteinander kombiniert. GridSearchCV wendet automatisch auch Cross Validation an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "\n",
    "# Liste an Hyperparametern\n",
    "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "\n",
    "# Modell anlegen\n",
    "grid_log_model = GridSearchCV(log_model, param_grid = grid_values,scoring = 'accuracy', cv=10)\n",
    "\n",
    "# Modell trainieren\n",
    "grid_log_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show best Hyperparameters and best Cross Validation Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters: \", grid_log_model.best_params_)\n",
    "\n",
    "print(\"\\nBest Cross Validation Score      :\", grid_log_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2. Grid Search bei Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Grid Search für Support Vector Classifier können wir die Kernels (also z.B. linear, RBF) auch als Hyperparameter Liste angeben. Wenn es bei Ihnen zu lange dauert (~ mehr als 10 Minuten) können Sie gerne die Random Search ausprobieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legen Sie einen Support Vector Classifier ohne weitere Hyperparameter Angaben an\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "# Liste an Hyperparametern festlegen\n",
    "grid_values = {'C':[0.001,.009,0.01,.09,1,5,10,25], \n",
    "               'kernel':['linear', 'rbf'], \n",
    "               'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 100]}\n",
    "\n",
    "# Grid Search festlegen. Das Ausführen kann eine Weile dauern. \n",
    "\n",
    "grid_svc_model = GridSearchCV(svc,param_grid=grid_values,scoring='accuracy',n_jobs=1,cv=10)\n",
    "\n",
    "\n",
    "# Trainieren Sie den Classifier\n",
    "grid_svc_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters: \", grid_svc_model.best_params_)\n",
    "\n",
    "print(\"\\nBest Cross Validation Score      :\", grid_svc_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 2. Random Search bei Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Grid Search kann bei einer größeren Anzahl an Hyperparametern sehr lange dauern. Etwas effizienter ist dabei die Random Search, bei der die Hyperparameter zufällig miteinander kombiniert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_svc_model = RandomizedSearchCV(svc,param_distributions=grid_values,scoring='accuracy',n_jobs=1,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_svc_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters: \", random_svc_model.best_params_)\n",
    "\n",
    "print(\"\\nBest Cross Validation Score      :\", random_svc_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weitere Ressourcen:\n",
    "\n",
    "- Chris Albon ist Autor von dem gern genutzten \"Machine Learning with Python Cookbook\". Auf seiner Seite finden sich ziemlich viele und gute Ressourcen https://chrisalbon.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
